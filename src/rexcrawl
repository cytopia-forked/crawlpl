#!/usr/bin/perl
#
# cpan install LWP::Simple
#

use strict;
use warnings;

use LWP::Simple;
use LWP::UserAgent;
use HTTP::Request;
use HTTP::Response;

my @urls;
my %visited;
my $browser;

my $SLEEP = $ENV{REQUEST_PAUSE} // 1;
my $TIMEOUT = $ENV{REQUEST_TIMEOUT} // 15;

my $UAMOZ = 'Mozilla/5.0 (Windows NT 6.1; WOW64)';
my $UAENG = 'AppleWebKit/537.36 (KHTML, like Gecko)';
my $UATAG = 'Chrome/46.0.2490.86 Safari/537.36';

$browser = LWP::UserAgent->new(join(' ', $UAMOZ, $UAENG, $UATAG));
$browser->proxy( ['http'], $ENV{HTTP_PROXY} ) if exists $ENV{HTTP_PROXY};
$browser->timeout($TIMEOUT);

die("usage: rexcrawl url extract-pattern [crawl-pattern]") if(scalar @ARGV < 2);
my ($url, $extract, $crawl) = @ARGV;
push(@urls, $url);

foreach my $url (@urls) {

	next if exists $visited{$url};

	$visited{$url} = 1;

	my $request = HTTP::Request->new(GET => $url);
	my $response = $browser->request($request);

	if ($response->is_error()) {
		printf STDERR "rexcrawl: %s for %s\n", $response->status_line, $url;
		next;
	}

	my $content = $response->content(); 

	while($content =~ m/$extract/g) {
		my @matches = $& =~ m/$extract/;
		print join("\t",@matches)."\n";
	}

	if($crawl) {
		push @urls, $& while($content =~ m/$crawl/g);
	}

	sleep $SLEEP;
}
